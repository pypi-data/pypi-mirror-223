# Examples

Here are some examples to help you get started with the easyllm library:

## Hugging Face

| Example                                                                 | Description                                                                           |
| ----------------------------------------------------------------------- | ------------------------------------------------------------------------------------- |
| [Detailed ChatCompletion Example](chat-completion-api)                  | Shows how to use the ChatCompletion API to have a conversational chat with the model. |
| [Example how to stream chat requests](stream-chat-completions)          | Demonstrates streaming multiple chat requests to efficiently chat with the model.     |
| [Example how to stream text requests](stream-text-completions)          | Shows how to stream multiple text completion requests.                                |
| [Detailed Completion Example](text-completion-api)                      | Uses the TextCompletion API to generate text with the model.                          |
| [Create Embeddings](get-embeddings)                                     | Embeds text into vector representations using the model.                              |
| [Hugging Face Inference Endpoints Example](inference-endpoints-example) | Example on how to use custom endpoints, e.g. Inference Endpoints or localhost.        |

The examples cover the main functionality of the library - chat, text completion, and embeddings. Let me know if you would like me to modify or expand the index page in any way.